{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34064fad-db25-459b-a25e-9947f6f2b6c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This solution accelerator notebook is available at [Databricks Industry Solutions](https://github.com/databricks-industry-solutions/manufacturing-root-cause-analysis/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32cc9def-ba1a-4a18-8a61-9132af42e0f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fit Causal Models to Data\n",
    "\n",
    "In this second notebook, we will:\n",
    "\n",
    "1. Assign causal mechanisms to the causal graph defined in the previous notebook.\n",
    "2. Fit the causal models identified in the previous step to the causal graph.\n",
    "3. Evaluate the fitted graph to assess how well it represents the underlying data generation process.\n",
    "4. Register the fitted graph to Unity Catalog using MLflow for future use.\n",
    "\n",
    "See the notebook `01_causal_graph` for a recommended cluster configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c970c3b6-d86f-4da6-b6b4-bc3170049233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4df6e728-75ce-42ab-9fdb-f4e7f4c8f0b8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install graphviz from nicer visualization"
    }
   },
   "outputs": [],
   "source": [
    "%sh apt-get update && apt-get install -y graphviz graphviz-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ea7e7c-f7ee-408e-abb0-9ecfe41d696f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "022c39c6-92a8-46be-9713-f454e6130d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the next cell, we run the `99_utils` notebook, which defines a few utility functions that we will use along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c480a89-46ed-4ce6-bda6-5a199b52b606",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Run utils notebook"
    }
   },
   "outputs": [],
   "source": [
    "%run ./99_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ae59a67-cdba-42d1-aa14-a9b451a0e237",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define variables and set MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf33a68d-4832-4afd-8d7f-62ad9ee40e7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dowhy\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b103bbe-0a0e-4ecc-a205-17046de8dd49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_name = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "first_name = user_name.split(\".\")[0]\n",
    "\n",
    "# Set up Unity Catalog\n",
    "catalog = f'causal_solacc_{first_name}'     # Change this to your catalog name\n",
    "schema = f'rca'                             # Change this to your schema name\n",
    "model = f\"manufacturing_rca\"                # Change this to your model name\n",
    "\n",
    "setup_unity_catalog(catalog, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fabf0bf-bb23-4993-905e-13ddc01c066d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the experiment name\n",
    "experiment_name = f\"/Users/{user_name}/rca_manufacturing\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40453481-a5b0-47b5-aa28-41eb197f5ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the causal graph\n",
    "\n",
    "Now, let's load the causal graph defined in the previous notebook. We will integrate this graph with generative models that describe the data generation process at each node to construct a structural causal model (SCM).\n",
    "\n",
    "The causal graph can be loaded using MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "213992df-37f4-4c54-b178-9f61fd5551a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find all the runs from the prior notebook for causal discovery\n",
    "client = mlflow.MlflowClient()\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "discovery_runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id], \n",
    "    filter_string=\"attributes.run_name='causal_graph'\",\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1,\n",
    "    )\n",
    "\n",
    "# Make sure there is at least one run available\n",
    "assert len(discovery_runs) == 1, \"Run the previous notebook: 01_causal_graph\"\n",
    "\n",
    "# The only result should be the latest based on our search_runs call\n",
    "latest_discovery_run = discovery_runs[0]\n",
    "latest_discovery_run.info.artifact_uri\n",
    "\n",
    "# Load the graph artifact from the run\n",
    "local_path = mlflow.artifacts.download_artifacts(latest_discovery_run.info.artifact_uri + \"/graph/causal_graph.pickle\")\n",
    "\n",
    "with open(local_path, \"rb\") as f:\n",
    "    causal_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00c1862d-f952-4aa2-9ff1-a2480d429f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To verify, let's plot the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a448ce4-3a11-4dd2-bf96-45f8e1dabfdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dowhy.gcm.util.plot(causal_graph, figure_size=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c7e3471-9505-410d-a39a-4cafc766a464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "Next, we will load the synthetic dataset we generated in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb81fc1-d55a-4bfd-8e86-ae5effb6bb16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the Delta table name\n",
    "table_name = f\"{catalog}.{schema}.data_manufacturing\"\n",
    "\n",
    "# Query to retrieve the version history of the Delta table\n",
    "version_query = f\"DESCRIBE HISTORY {table_name}\"\n",
    "\n",
    "# Get the latest version of the Delta table\n",
    "version = spark.sql(version_query).collect()[0][0]\n",
    "\n",
    "# Read the Delta table as of the latest version\n",
    "sdf = spark.read.format(\"delta\").option(\"versionAsOf\", version).table(table_name)\n",
    "\n",
    "# Convert the Spark DataFrame to a pandas DataFrame\n",
    "pdf = sdf.toPandas()\n",
    "\n",
    "# Display the first few rows of the pandas DataFrame\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60bcf479-ff5f-45aa-a867-e5e4f17acdf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assign causal mechanisms to the graph\n",
    "\n",
    "As we can see, we have one sample for each processed product, including all the variables in the causal graph.\n",
    "\n",
    "While we have defined the causal graph, we still need to assign generative models to its nodes. These models can either be manually specified and configured if necessary or automatically inferred from the data using heuristics. Here, we will use the latter approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cb6b51d-9872-47d5-901a-a087751d7490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dowhy import gcm\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create the structural causal model object\n",
    "scm = gcm.StructuralCausalModel(causal_graph)\n",
    "\n",
    "# Automatically assign generative models to each node based on the given data\n",
    "auto_assignment_summary = gcm.auto.assign_causal_mechanisms(\n",
    "  scm, \n",
    "  pdf, \n",
    "  override_models=True, \n",
    "  quality=gcm.auto.AssignmentQuality.GOOD\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cca5424-4986-47dd-ab87-5fcd0306ab4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Whenever possible, it is best practice to assign models based on prior knowledge, as this ensures they closely reflect the underlying physics of the domain rather than relying on data-specific nuances. However, in this case, we have asked DoWhy to handle this task for us.\n",
    "\n",
    "Once the models are automatically assigned, we can print a summary to gain insights into the selected models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6473fa6a-42a1-42f4-b31d-cc0dcea3ffa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(auto_assignment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf268f44-b618-4357-b1b0-f8d175a6cd47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The auto-assignment function evaluates both linear and non-linear models for non-root nodes, considering Additive Noise Models (ANMs) for continuous data (e.g., position_alignment) and Discrete ANMs for discrete data (e.g., dimensions), selecting the best-performing model based on metrics such as MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c227a12d-e138-49f8-b8aa-df979ec95f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fit causal models to the data\n",
    "\n",
    "After assigning a model to each node, we need to learn the parameters of the model. We fit the causal model to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84642d7b-6bf0-44d6-a657-87bc0792ddba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gcm.fit(scm, pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e76b54f-1d32-4aec-bb24-445106319982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the fitted causal models\n",
    "\n",
    "The fit method trains the generative models for each node by learning their parameters. Let's examine the performance of these causal mechanisms and evaluate how well they capture the underlying distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56a991b8-f948-4cfe-a900-2dab6c4d166d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "  gcm.evaluate_causal_model(\n",
    "  scm,\n",
    "  pdf, \n",
    "  compare_mechanism_baselines=True, \n",
    "  evaluate_invertibility_assumptions=True)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f006af2d-e779-449e-878b-a3e992d46305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Broadly, the `gcm.evaluate_causal_model` method performs four types of evaluations on the fitted graph: evaluation of causal mechanisms, assessment of the invertible functional causal model assumption, evaluation of the generated distribution, and analysis of the causal graph structure. While we won't delve into the details of these tests here, we encourage users to check DoWhy's [documentation](https://www.pywhy.org/dowhy/v0.11.1/user_guide/modeling_gcm/model_evaluation.html) and [source code](https://github.com/py-why/dowhy/blob/main/dowhy/gcm/model_evaluation.py) for a deeper understanding.\n",
    "\n",
    "In our case, using a synthetically generated dataset, the fitted causal mechanisms largely align well with the data generation process. The above graph provides strong evidence that the causal graph structure identified in the model is capturing real and meaningful relationships in the data, rather than random associations. The extremely low p-values and clear separation between the original and permuted graphs suggest that the causal graph has successfully identified genuine structural relationships in the system being studied. \n",
    "\n",
    "However, in real-world scenarios, datasets are often messier, have smaller sample sizes, or exhibit lower signal-to-noise ratios. In addition, the graph might be missing key confounders. For these reasons, it’s crucial to understand the evaluation techniques mentioned above and recognize how each test addresses specific issues.\n",
    "\n",
    "If the evaluation results indicate signs of misspecification, you can choose to revisit steps such as data collection, causal discovery, or modeling of causal mechanisms, or proceed with your analysis despite the issues. The evaluations provide insights into the quality of the causal model but they should not be overinterpreted, as some causal relationships are inherently challenging to model. Additionally, many algorithms demonstrate robustness to misspecifications or suboptimal performance of causal mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46da2fe2-1353-4b5b-97e6-e01110fb9aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the fitted causal graph to Unity Catalog using MLflow\n",
    "\n",
    "Once we are satisfied with our causal models, we can register it with Unity Catalog to ensure proper governance. Later, we will load this model to perform causal analysis. MLflow does not natively support the `gcm.StructuralCausalModel` (SCM) object, but we can simply wrap the SCM object using `mlflow.pyfunc.PythonModel` and log it with MLflow instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0ac22b-5337-4379-933d-7501d7ef503c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "class SCM(mlflow.pyfunc.PythonModel):\n",
    "  def __init__(self, scm, causal_graph, target_node):\n",
    "    from dowhy import gcm\n",
    "    import pandas as pd\n",
    "    self.scm = scm\n",
    "    self.causal_graph = causal_graph\n",
    "    self.target_node = target_node\n",
    "\n",
    "  def load_scm(self):\n",
    "    return self.scm\n",
    "  \n",
    "  def load_causal_graph(self):\n",
    "    return self.causal_graph\n",
    "  \n",
    "  def predict(self, context, input_df):\n",
    "    return pd.DataFrame(gcm.attribute_anomalies(self.scm, target_node=self.target_node, anomaly_samples=input_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a273251c-489c-4797-9572-403111c4df06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dowhy import gcm\n",
    "import sklearn\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "from mlflow.data.spark_dataset import SparkDataset\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import DataType, Schema, ColSpec\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Define the input example for the model and infer its input-output signature\n",
    "input_example = pdf.iloc[[0]]  # Select a single row as an input example\n",
    "signature = infer_signature(\n",
    "    model_input=input_example, \n",
    "    model_output=pd.DataFrame(gcm.attribute_anomalies(scm, target_node=\"quality\", anomaly_samples=input_example)),\n",
    ")\n",
    "\n",
    "# Set the registered model name based on catalog, schema, and model\n",
    "registered_model_name = f\"{catalog}.{schema}.{model}\"\n",
    "\n",
    "# Start an MLflow run to log the causal model and its related metadata\n",
    "with mlflow.start_run(run_name=\"causal_model\") as run:\n",
    "    # Log the causal model using MLflow's pyfunc interface\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"model\",\n",
    "        python_model=SCM(scm, causal_graph, \"quality\"),  # Wrap the SCM object in a custom Python model\n",
    "        pip_requirements=[\n",
    "            \"dowhy==\" + dowhy.__version__,  # Log required package versions\n",
    "            \"pandas==\" + pd.__version__,\n",
    "            \"numpy==\" + np.__version__,\n",
    "            \"scikit-learn==\" + sklearn.__version__,\n",
    "        ],\n",
    "        signature=signature,  # Log the inferred input-output signature\n",
    "        input_example=input_example,  # Log an example input\n",
    "        registered_model_name=registered_model_name,  # Register the model in Unity Catalog\n",
    "    )\n",
    "    \n",
    "    # Log parameters related to the model's configuration or settings\n",
    "    mlflow.log_params({\n",
    "        **{\n",
    "            \"override_models\": \"True\",  # Specify if existing models should be overridden\n",
    "            \"quality\": \"gcm.auto.AssignmentQuality.GOOD\",  # Record the quality of assignments\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Log the causal graph artifact for reference or reuse\n",
    "    mlflow.log_artifact(local_path, artifact_path=\"causal_graph\")\n",
    "    \n",
    "    # Log the input dataset used during the training or analysis process\n",
    "    mlflow.log_input(\n",
    "        mlflow.data.from_spark(df=sdf, table_name=table_name, version=version),  # Input dataset information\n",
    "        context=\"training\",  # Context of the dataset usage\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e520b1e-1385-4963-a411-5fcb72443e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's assign the \"champion\" alias to the newly registered model. This makes it easier to load this specific version later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a8e431c-dbef-4f7f-8b4b-921e10c6d176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "# Assign an alias to the latest model version\n",
    "def get_latest_model_version(mlflow_client, registered_name):\n",
    "    latest_version = 1\n",
    "    for mv in mlflow_client.search_model_versions(f\"name='{registered_name}'\"):\n",
    "        version_int = int(mv.version)\n",
    "        if version_int > latest_version:\n",
    "            latest_version = version_int\n",
    "    return latest_version\n",
    "\n",
    "\n",
    "model_version = get_latest_model_version(mlflow_client, registered_model_name)\n",
    "mlflow_client.set_registered_model_alias(registered_model_name, \"champion\", model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd7db034-4acd-4443-9f90-5605e9bfe654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Wrap up\n",
    "\n",
    "This concludes the second notebook. Here, we assigned causal mechanisms to the causal graph defined in the previous notebook. We then fitted the graph on the dataset and evaluated the fitted graph to assess how well it captures the underlying data generation process. Finally, we registered the fitted graph in Unity Catalog using MLflow for future use. \n",
    "\n",
    "In the next notebook, we will leverage the fitted graph to conduct causal analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d04dbbd-db80-4193-a4ed-d65eb61ec81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "© 2025 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License. All included or referenced third party libraries are subject to the licenses set forth below.\n",
    "\n",
    "| library                                | description             | license    | source                                              |\n",
    "|----------------------------------------|-------------------------|------------|-----------------------------------------------------|\n",
    "| Graphviz | An open source graph visualization software | Common Public License Version 1.0 | https://graphviz.org/download/\n",
    "| pygraphviz | A Python interface to the Graphviz graph layout and visualization package | BSD | https://pypi.org/project/pygraphviz/\n",
    "| networkx | A Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. | BSD | https://pypi.org/project/networkx/\n",
    "| dowhy | A Python library for causal inference that supports explicit modeling and testing of causal assumptions | MIT | https://pypi.org/project/dowhy/\n",
    "| causal-learn | A python package for causal discovery that implements both classical and state-of-the-art causal discovery algorithms, which is a Python translation and extension of Tetrad. | MIT | https://pypi.org/project/causal-learn/\n",
    "| lime | Local Interpretable Model-Agnostic Explanations for machine learning classifiers | BSD | https://pypi.org/project/lime/\n",
    "| shap | A unified approach to explain the output of any machine learning model | MIT | https://pypi.org/project/shap/"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_causal_modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
